{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seismic Event Detection using SeisBench\n",
    "\n",
    "This notebook demonstrates the complete workflow for seismic event detection using SeisBench models,\n",
    "following the approach from real-time detection systems.\n",
    "\n",
    "## Workflow\n",
    "1. Load pre-trained SeisBench model (PhaseNet, EQTransformer, or QuakeXNet)\n",
    "2. Download seismic data from FDSN client\n",
    "3. Run model inference to get probability predictions\n",
    "4. Detect event windows from probabilities\n",
    "5. Interactive visualization for quality control\n",
    "6. Export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from obspy import UTCDateTime\n",
    "from obspy.clients.fdsn import Client\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "from src.seisbench_models import create_detector, SeismicDetector\n",
    "from src.detect import smooth_moving_avg, detect_event_windows, multi_class_detection\n",
    "from src.interactive_plots import plot_detection_results, interactive_detection_viewer, plot_event_summary\n",
    "from src.utils import ensure_dir\n",
    "\n",
    "# For interactive plots in Jupyter\n",
    "%matplotlib widget\n",
    "# Or use: %matplotlib inline\n",
    "\n",
    "print(\"✓ Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "config = {\n",
    "    # Model settings\n",
    "    'model_name': 'phasenet',  # Options: 'phasenet', 'eqtransformer', 'gpd'\n",
    "    'model_version': 'original',\n",
    "    'use_quakescope': False,  # Set to True to use QuakeScope models\n",
    "    'device': 'auto',  # 'auto', 'cpu', or 'cuda'\n",
    "    \n",
    "    # Data settings\n",
    "    'network': 'UW',\n",
    "    'station': 'RATT',\n",
    "    'channel': 'HH*',  # HH* for high-bandwidth, BH* for broadband\n",
    "    'location': '*',\n",
    "    \n",
    "    # Time window (use recent data or specify custom)\n",
    "    'use_recent': True,  # If True, use last 24 hours\n",
    "    'hours_back': 24,\n",
    "    'starttime': '2024-01-01T00:00:00',  # Used if use_recent=False\n",
    "    'endtime': '2024-01-01T01:00:00',\n",
    "    \n",
    "    # Detection parameters\n",
    "    'threshold': 0.5,\n",
    "    'min_duration': 10,  # samples\n",
    "    'merge_distance': 50,  # samples\n",
    "    'apply_smoothing': True,\n",
    "    'smooth_window': 100,\n",
    "    \n",
    "    # Output settings\n",
    "    'save_plots': True,\n",
    "    'save_results': True,\n",
    "}\n",
    "\n",
    "# Create output directories\n",
    "ensure_dir('../plots')\n",
    "ensure_dir('../logs')\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Pre-trained SeisBench Model\n",
    "\n",
    "We'll load a pre-trained model from SeisBench. These models are trained on large\n",
    "seismic datasets and can detect various types of events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create detector\n",
    "print(f\"Loading {config['model_name']} model...\")\n",
    "\n",
    "detector = create_detector(\n",
    "    model_name=config['model_name'],\n",
    "    version=config['model_version'],\n",
    "    device=config['device'],\n",
    "    use_quakescope=config['use_quakescope']\n",
    ")\n",
    "\n",
    "print(f\"✓ Model loaded successfully on {detector.device}\")\n",
    "print(f\"  Model: {detector.model_name}\")\n",
    "print(f\"  Version: {detector.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download Seismic Data\n",
    "\n",
    "Download data from IRIS/FDSN data center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up time window\n",
    "if config['use_recent']:\n",
    "    endtime = UTCDateTime.now()\n",
    "    starttime = endtime - config['hours_back'] * 3600\n",
    "else:\n",
    "    starttime = UTCDateTime(config['starttime'])\n",
    "    endtime = UTCDateTime(config['endtime'])\n",
    "\n",
    "print(f\"Time window:\")\n",
    "print(f\"  Start: {starttime}\")\n",
    "print(f\"  End: {endtime}\")\n",
    "print(f\"  Duration: {(endtime - starttime) / 3600:.1f} hours\")\n",
    "\n",
    "# Download data\n",
    "print(f\"\\nDownloading data for {config['network']}.{config['station']}...\")\n",
    "\n",
    "client = Client(\"IRIS\")\n",
    "\n",
    "try:\n",
    "    stream = client.get_waveforms(\n",
    "        network=config['network'],\n",
    "        station=config['station'],\n",
    "        channel=config['channel'],\n",
    "        location=config['location'],\n",
    "        starttime=starttime,\n",
    "        endtime=endtime\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ Downloaded {len(stream)} traces\")\n",
    "    print(f\"\\nStream info:\")\n",
    "    print(stream)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error downloading data: {e}\")\n",
    "    print(\"\\nTip: Try different station/network or time window\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Model Inference\n",
    "\n",
    "Use SeisBench's `annotate()` method to get probability predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running model inference...\")\n",
    "\n",
    "# Run inference using SeisBench annotate\n",
    "annotated_stream = detector.annotate(\n",
    "    stream,\n",
    "    batch_size=32,\n",
    "    overlap=0\n",
    ")\n",
    "\n",
    "print(f\"✓ Inference complete\")\n",
    "print(f\"\\nAnnotated stream:\")\n",
    "print(annotated_stream)\n",
    "\n",
    "# Extract predictions by class\n",
    "# Common class names: P (P-wave), S (S-wave), N (Noise)\n",
    "# or: eq (earthquake), px (explosion), su (surface event)\n",
    "probabilities = detector._extract_predictions(annotated_stream)\n",
    "\n",
    "print(f\"\\nPrediction classes:\")\n",
    "for class_name, probs in probabilities.items():\n",
    "    print(f\"  {class_name}: {len(probs)} samples, max prob: {np.max(probs):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Detect Event Windows\n",
    "\n",
    "Apply smoothing and threshold-based detection to find event windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Detecting event windows...\")\n",
    "\n",
    "# Detect events for each class\n",
    "events = multi_class_detection(\n",
    "    probabilities,\n",
    "    threshold=config['threshold'],\n",
    "    min_duration=config['min_duration'],\n",
    "    merge_distance=config['merge_distance'],\n",
    "    apply_smoothing=config['apply_smoothing'],\n",
    "    smooth_window=config['smooth_window']\n",
    ")\n",
    "\n",
    "print(f\"✓ Detection complete\")\n",
    "print(f\"\\nDetected events:\")\n",
    "total_events = 0\n",
    "for class_name, class_events in events.items():\n",
    "    print(f\"  {class_name}: {len(class_events)} events\")\n",
    "    total_events += len(class_events)\n",
    "\n",
    "print(f\"\\nTotal events: {total_events}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Event Summary DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert events to DataFrame for easier analysis\n",
    "event_records = []\n",
    "sampling_rate = stream[0].stats.sampling_rate\n",
    "\n",
    "for class_name, class_events in events.items():\n",
    "    for event in class_events:\n",
    "        start_idx = event['start']\n",
    "        end_idx = event['end']\n",
    "        start_time = starttime + (start_idx / sampling_rate)\n",
    "        end_time = starttime + (end_idx / sampling_rate)\n",
    "        \n",
    "        event_records.append({\n",
    "            'station': config['station'],\n",
    "            'network': config['network'],\n",
    "            'class': class_name,\n",
    "            'start_index': start_idx,\n",
    "            'end_index': end_idx,\n",
    "            'duration': event['duration'],\n",
    "            'start_time': str(start_time),\n",
    "            'end_time': str(end_time),\n",
    "            'max_prob': event['max_prob'],\n",
    "            'mean_prob': event['mean_prob'],\n",
    "            'auc': event['area_under_curve'],\n",
    "        })\n",
    "\n",
    "if event_records:\n",
    "    df_events = pd.DataFrame(event_records)\n",
    "    print(\"Event Summary:\")\n",
    "    print(df_events.to_string())\n",
    "    \n",
    "    # Save to CSV\n",
    "    if config['save_results']:\n",
    "        csv_path = f\"../logs/{config['station']}_{starttime.date}_events.csv\"\n",
    "        df_events.to_csv(csv_path, index=False)\n",
    "        print(f\"\\n✓ Results saved to {csv_path}\")\n",
    "else:\n",
    "    print(\"No events detected\")\n",
    "    df_events = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization - Detection Results\n",
    "\n",
    "Plot waveforms with probability predictions and detected event windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot detection results\n",
    "save_path = None\n",
    "if config['save_plots']:\n",
    "    save_path = f\"../plots/{config['station']}_{starttime.date}_detection.png\"\n",
    "\n",
    "fig, axes = plot_detection_results(\n",
    "    stream,\n",
    "    probabilities,\n",
    "    events,\n",
    "    sampling_rate=sampling_rate,\n",
    "    figsize=(15, 10),\n",
    "    save_path=save_path\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Interactive Quality Control Viewer\n",
    "\n",
    "Use interactive plots to review detections and toggle event classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive viewer with controls\n",
    "if total_events > 0:\n",
    "    fig_interactive = interactive_detection_viewer(\n",
    "        stream,\n",
    "        probabilities,\n",
    "        events,\n",
    "        sampling_rate=sampling_rate\n",
    "    )\n",
    "else:\n",
    "    print(\"No events to display in interactive viewer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Event Statistics Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot event statistics\n",
    "if total_events > 0:\n",
    "    save_path = None\n",
    "    if config['save_plots']:\n",
    "        save_path = f\"../plots/{config['station']}_{starttime.date}_summary.png\"\n",
    "    \n",
    "    fig_summary, axes_summary = plot_event_summary(\n",
    "        events,\n",
    "        sampling_rate=sampling_rate,\n",
    "        figsize=(12, 8),\n",
    "        save_path=save_path\n",
    "    )\n",
    "    \n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No events to summarize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export Results for Further Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "if df_events is not None:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DETECTION SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Station: {config['network']}.{config['station']}\")\n",
    "    print(f\"Time window: {starttime} to {endtime}\")\n",
    "    print(f\"Duration: {(endtime - starttime) / 3600:.1f} hours\")\n",
    "    print(f\"\\nTotal events detected: {len(df_events)}\")\n",
    "    print(\"\\nEvents by class:\")\n",
    "    print(df_events['class'].value_counts())\n",
    "    print(\"\\nProbability statistics:\")\n",
    "    print(df_events[['class', 'max_prob', 'mean_prob']].groupby('class').describe())\n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"No events detected in this time window\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- **Try different models**: PhaseNet, EQTransformer, GPD\n",
    "- **Adjust detection parameters**: threshold, min_duration, merge_distance\n",
    "- **Process multiple stations**: Loop through a station list\n",
    "- **Real-time monitoring**: Adapt for continuous detection\n",
    "- **Custom models**: Load QuakeScope or custom trained weights\n",
    "- **Advanced filtering**: Apply additional quality control filters\n",
    "- **Catalog comparison**: Compare with earthquake catalogs\n",
    "\n",
    "## References\n",
    "\n",
    "- SeisBench Documentation: https://seisbench.readthedocs.io/\n",
    "- ObsPy Documentation: https://docs.obspy.org/\n",
    "- QuakeScope Models: https://github.com/quakescope\n",
    "- PNW Seismic Event Classification: https://github.com/Akashkharita/PNW_Seismic_Event_Classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
